@article{aihara2011,
  title = {The {{Eighth Data Release}} of the {{Sloan Digital Sky Survey}}: {{First Data}} from {{SDSS-III}}},
  shorttitle = {The {{Eighth Data Release}} of the {{Sloan Digital Sky Survey}}},
  author = {Aihara, Hiroaki and Allende Prieto, Carlos and An, Deokkeun and Anderson, Scott F. and Aubourg, {\'E}ric and Balbinot, Eduardo and Beers, Timothy C. and Berlind, Andreas A. and Bickerton, Steven J. and Bizyaev, Dmitry and Blanton, Michael R. and Bochanski, John J. and Bolton, Adam S. and Bovy, Jo and Brandt, W. N. and Brinkmann, J. and Brown, Peter J. and Brownstein, Joel R. and Busca, Nicolas G. and Campbell, Heather and Carr, Michael A. and Chen, Yanmei and Chiappini, Cristina and Comparat, Johan and Connolly, Natalia and Cortes, Marina and Croft, Rupert A. C. and Cuesta, Antonio J. and {da Costa}, Luiz N. and Davenport, James R. A. and Dawson, Kyle and Dhital, Saurav and Ealet, Anne and Ebelke, Garrett L. and Edmondson, Edward M. and Eisenstein, Daniel J. and Escoffier, Stephanie and Esposito, Massimiliano and Evans, Michael L. and Fan, Xiaohui and Femen{\'i}a Castell{\'a}, Bruno and {Font-Ribera}, Andreu and Frinchaboy, Peter M. and Ge, Jian and Gillespie, Bruce A. and Gilmore, G. and Gonz{\'a}lez Hern{\'a}ndez, Jonay I. and Gott, J. Richard and Gould, Andrew and Grebel, Eva K. and Gunn, James E. and Hamilton, Jean-Christophe and Harding, Paul and Harris, David W. and Hawley, Suzanne L. and Hearty, Frederick R. and Ho, Shirley and Hogg, David W. and Holtzman, Jon A. and Honscheid, Klaus and Inada, Naohisa and Ivans, Inese I. and Jiang, Linhua and Johnson, Jennifer A. and Jordan, Cathy and Jordan, Wendell P. and Kazin, Eyal A. and Kirkby, David and Klaene, Mark A. and Knapp, G. R. and Kneib, Jean-Paul and Kochanek, C. S. and Koesterke, Lars and Kollmeier, Juna A. and Kron, Richard G. and Lampeitl, Hubert and Lang, Dustin and Le Goff, Jean-Marc and Lee, Young Sun and Lin, Yen-Ting and Long, Daniel C. and Loomis, Craig P. and Lucatello, Sara and Lundgren, Britt and Lupton, Robert H. and Ma, Zhibo and MacDonald, Nicholas and Mahadevan, Suvrath and Maia, Marcio A. G. and Makler, Martin and Malanushenko, Elena and Malanushenko, Viktor and Mandelbaum, Rachel and Maraston, Claudia and Margala, Daniel and Masters, Karen L. and McBride, Cameron K. and McGehee, Peregrine M. and McGreer, Ian D. and M{\'e}nard, Brice and {Miralda-Escud{\'e}}, Jordi and Morrison, Heather L. and Mullally, F. and Muna, Demitri and Munn, Jeffrey A. and Murayama, Hitoshi and Myers, Adam D. and Naugle, Tracy and Neto, Angelo Fausti and Nguyen, Duy Cuong and Nichol, Robert C. and O'Connell, Robert W. and Ogando, Ricardo L. C. and Olmstead, Matthew D. and Oravetz, Daniel J. and Padmanabhan, Nikhil and {Palanque-Delabrouille}, Nathalie and Pan, Kaike and Pandey, Parul and P{\^a}ris, Isabelle and Percival, Will J. and Petitjean, Patrick and Pfaffenberger, Robert and Pforr, Janine and Phleps, Stefanie and Pichon, Christophe and Pieri, Matthew M. and Prada, Francisco and {Price-Whelan}, Adrian M. and Raddick, M. Jordan and Ramos, Beatriz H. F. and Reyl{\'e}, C{\'e}line and Rich, James and Richards, Gordon T. and Rix, Hans-Walter and Robin, Annie C. and {Rocha-Pinto}, Helio J. and Rockosi, Constance M. and Roe, Natalie A. and Rollinde, Emmanuel and Ross, Ashley J. and Ross, Nicholas P. and Rossetto, Bruno M. and S{\'a}nchez, Ariel G. and Sayres, Conor and Schlegel, David J. and Schlesinger, Katharine J. and Schmidt, Sarah J. and Schneider, Donald P. and Sheldon, Erin and Shu, Yiping and Simmerer, Jennifer and Simmons, Audrey E. and Sivarani, Thirupathi and Snedden, Stephanie A. and Sobeck, Jennifer S. and Steinmetz, Matthias and Strauss, Michael A. and Szalay, Alexander S. and Tanaka, Masayuki and Thakar, Aniruddha R. and Thomas, Daniel and Tinker, Jeremy L. and Tofflemire, Benjamin M. and Tojeiro, Rita and Tremonti, Christy A. and Vandenberg, Jan and Vargas Maga{\~n}a, M. and Verde, Licia and Vogt, Nicole P. and Wake, David A. and Wang, Ji and Weaver, Benjamin A. and Weinberg, David H. and White, Martin and White, Simon D. M. and Yanny, Brian and Yasuda, Naoki and Yeche, Christophe and Zehavi, Idit},
  year = {2011},
  month = apr,
  journal = {The Astrophysical Journal Supplement Series},
  volume = {193},
  pages = {29},
  issn = {0067-0049},
  doi = {10.1088/0067-0049/193/2/29},
  urldate = {2018-08-14},
  abstract = {The Sloan Digital Sky Survey (SDSS) started a new phase in 2008 August,  with new instrumentation and new surveys focused on Galactic structure and chemical evolution, measurements of the baryon oscillation feature in the clustering of galaxies and the quasar Ly{$\alpha$} forest, and a radial velocity search for planets around \textasciitilde 8000 stars. This paper describes the first data release of SDSS-III (and the eighth counting from the beginning of the SDSS). The release includes five-band imaging of roughly 5200 deg2 in the southern Galactic cap, bringing the total footprint of the SDSS imaging to 14,555 deg2, or over a third of the Celestial Sphere. All the imaging data have been reprocessed with an improved sky-subtraction algorithm and a final, self-consistent photometric recalibration and flat-field determination. This release also includes all data from the second phase of the Sloan Extension for Galactic Understanding and Exploration (SEGUE-2), consisting of spectroscopy of approximately 118,000 stars at both high and low Galactic latitudes. All the more than half a million stellar spectra obtained with the SDSS spectrograph have been reprocessed through an improved stellar parameter pipeline, which has better determination of metallicity for high-metallicity stars.},
  keywords = {atlases,catalogs,surveys},
  file = {/Users/chahah/Zotero/storage/S2ZVH2XJ/Aihara et al. - 2011 - The Eighth Data Release of the Sloan Digital Sky S.pdf}
}

@misc{akiba2019,
  title = {Optuna: {{A Next-generation Hyperparameter Optimization Framework}}},
  shorttitle = {Optuna},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  year = {2019},
  month = jul,
  number = {arXiv:1907.10902},
  eprint = {1907.10902},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.10902},
  urldate = {2023-04-05},
  abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/chahah/Zotero/storage/RT5BTG2Z/Akiba et al. - 2019 - Optuna A Next-generation Hyperparameter Optimizat.pdf;/Users/chahah/Zotero/storage/IPFTRX8S/1907.html}
}

@article{alsing2019,
  title = {Fast Likelihood-Free Cosmology with Neural Density Estimators and Active Learning},
  author = {Alsing, Justin and Charnock, Tom and Feeney, Stephen and Wandelt, Benjamin},
  year = {2019},
  month = sep,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {488},
  pages = {4440--4458},
  issn = {0035-8711},
  doi = {10.1093/mnras/stz1960},
  urldate = {2021-09-16},
  abstract = {Likelihood-free inference provides a framework for performing rigorous Bayesian inference using only forward simulations, properly accounting for all physical and observational effects that can be successfully included in the simulations. The key challenge for likelihood-free applications in cosmology, where simulation is typically expensive, is developing methods that can achieve high-fidelity posterior inference with as few simulations as possible. Density-estimation likelihood-free inference (DELFI) methods turn inference into a density-estimation task on a set of simulated data-parameter pairs, and give orders of magnitude improvements over traditional Approximate Bayesian Computation approaches to likelihood-free inference. In this paper, we use neural density estimators (NDEs) to learn the likelihood function from a set of simulated data sets, with active learning to adaptively acquire simulations in the most relevant regions of parameter space on the fly. We demonstrate the approach on a number of cosmological case studies, showing that for typical problems high-fidelity posterior inference can be achieved with just O(10\^3) simulations or fewer. In addition to enabling efficient simulation-based inference, for simple problems where the form of the likelihood is known, DELFI offers a fast alternative to Markov Chain Monte Carlo (MCMC) sampling, giving orders of magnitude speed-up in some cases. Finally, we introduce PYDELFI - a flexible public implementation of DELFI with NDEs and active learning - available at https://github.com/justinalsing/pydelfi.},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,data analysis: methods},
  annotation = {ADS Bibcode: 2019MNRAS.488.4440A},
  file = {/Users/chahah/Zotero/storage/5TTD68U3/Alsing et al. - 2019 - Fast likelihood-free cosmology with neural density.pdf}
}

@article{blanton2007,
  title = {K-Corrections and Filter Transformations in the Ultraviolet, Optical, and near Infrared},
  author = {Blanton, Michael R. and Roweis, Sam},
  year = {2007},
  month = feb,
  journal = {The Astronomical Journal},
  volume = {133},
  number = {2},
  eprint = {astro-ph/0606170},
  pages = {734--754},
  issn = {0004-6256, 1538-3881},
  doi = {10.1086/510127},
  urldate = {2019-02-04},
  abstract = {Template fits to observed galaxy fluxes allow calculation of K-corrections and conversions among observations of galaxies at various wavelengths. We present a method for creating model-based template sets given a set of heterogeneous photometric and spectroscopic galaxy data. Our technique, non-negative matrix factorization, is akin to principle component analysis (PCA), except that it is constrained to produce nonnegative templates, it can use a basis set of models (rather than the delta function basis of PCA), and it naturally handles uncertainties, missing data, and heterogeneous data (including broad-band fluxes at various redshifts). The particular implementation we present here is suitable for ultraviolet, optical, and near-infrared observations in the redshift range 0 {$<$} z {$<$} 1.5. Since we base our templates on stellar population synthesis models, the results are intepretable in terms of approximate stellar masses and star-formation histories. We present templates fit with this method to data from GALEX, Sloan Digital Sky Survey spectroscopy and photometry, the Two-Micron All Sky Survey, the Deep Extragalactic Evolutionary Probe and the Great Observatories Origins Deep Survey. In addition, we present software for using such data to estimate K-corrections and stellar masses.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics},
  file = {/Users/chahah/Zotero/storage/AJUMCPBH/Blanton and Roweis - 2007 - K-corrections and filter transformations in the ul.pdf;/Users/chahah/Zotero/storage/LPPXVIL3/0606170.html}
}

@article{blanton2011,
  title = {Improved {{Background Subtraction}} for the {{Sloan Digital Sky Survey Images}}},
  author = {Blanton, Michael R. and Kazin, Eyal and Muna, Demitri and Weaver, Benjamin A. and {Price-Whelan}, Adrian},
  year = {2011},
  month = jul,
  journal = {The Astronomical Journal},
  volume = {142},
  pages = {31},
  issn = {0004-6256},
  doi = {10.1088/0004-6256/142/1/31},
  urldate = {2018-05-11},
  abstract = {We describe a procedure for background subtracting Sloan Digital Sky Survey (SDSS) imaging that improves the resulting detection and photometry of large galaxies on the sky. Within each SDSS drift scan run, we mask out detected sources and then fit a smooth function to the variation of the sky background. This procedure has been applied to all SDSS-III Data Release 8 images, and the results are available as part of that data set. We have tested the effect of our background subtraction on the photometry of large galaxies by inserting fake galaxies into the raw pixels, reanalyzing the data, and measuring them after background subtraction. Our technique results in no size-dependent bias in galaxy fluxes up to half-light radii r 50 \textasciitilde{} 100 arcsec; in contrast, for galaxies of that size the standard SDSS photometric catalog underestimates fluxes by about 1.5 mag. Our results represent a substantial improvement over the standard SDSS catalog results and should form the basis of any analysis of nearby galaxies using the SDSS imaging data.},
  keywords = {atmospheric effects,galaxies: photometry,methods: data analysis,techniques: image processing},
  file = {/Users/chahah/Zotero/storage/FJ9HWCKC/Blanton et al. - 2011 - Improved Background Subtraction for the Sloan Digi.pdf}
}

@article{chabrier2003,
  title = {Galactic {{Stellar}} and {{Substellar Initial Mass Function}}},
  author = {Chabrier, Gilles},
  year = {2003},
  month = jul,
  journal = {Publications of the Astronomical Society of the Pacific},
  volume = {115},
  pages = {763--795},
  issn = {0004-6280},
  doi = {10.1086/376392},
  abstract = {We review recent determinations of the present-day mass function (PDMF) and initial mass function (IMF) in various components of the Galaxy-disk, spheroid, young, and globular clusters-and in conditions characteristic of early star formation. As a general feature, the IMF is found to depend weakly on the environment and to be well described by a power-law form for m{$>\sptilde$}1 Msolar and a lognormal form below, except possibly for early star formation conditions. The disk IMF for single objects has a characteristic mass around mc\textasciitilde 0.08 Msolar and a variance in logarithmic mass {$\sigma\sptilde$}0.7, whereas the IMF for multiple systems has mc\textasciitilde 0.2 Msolar and {$\sigma\sptilde$}0.6. The extension of the single MF into the brown dwarf regime is in good agreement with present estimates of L- and T-dwarf densities and yields a disk brown dwarf number density comparable to the stellar one, nBD\textasciitilde n*\textasciitilde 0.1 pc-3. The IMF of young clusters is found to be consistent with the disk field IMF, providing the same correction for unresolved binaries, confirming the fact that young star clusters and disk field stars represent the same stellar population. Dynamical effects, yielding depletion of the lowest mass objects, are found to become consequential for ages {$>\sptilde$}130 Myr. The spheroid IMF relies on much less robust grounds. The large metallicity spread in the local subdwarf photometric sample, in particular, remains puzzling. Recent observations suggest that there is a continuous kinematic shear between the thick-disk population, present in local samples, and the genuine spheroid one. This enables us to derive only an upper limit for the spheroid mass density and IMF. Within all the uncertainties, the latter is found to be similar to the one derived for globular clusters and is well represented also by a lognormal form with a characteristic mass slightly larger than for the disk, mc\textasciitilde 0.2-0.3 Msolar, excluding a significant population of brown dwarfs in globular clusters and in the spheroid. The IMF characteristic of early star formation at large redshift remains undetermined, but different observational constraints suggest that it does not extend below \textasciitilde 1 Msolar. These results suggest a characteristic mass for star formation that decreases with time, from conditions prevailing at large redshift to conditions characteristic of the spheroid (or thick disk) to present-day conditions. These conclusions, however, remain speculative, given the large uncertainties in the spheroid and early star IMF determinations. These IMFs allow a reasonably robust determination of the Galactic present-day and initial stellar and brown dwarf contents. They also have important galactic implications beyond the Milky Way in yielding more accurate mass-to-light ratio determinations. The mass-to-light ratios obtained with the disk and the spheroid IMF yield values 1.8-1.4 times smaller than for a Salpeter IMF, respectively, in agreement with various recent dynamical determinations. This general IMF determination is examined in the context of star formation theory. None of the theories based on a Jeans-type mechanism, where fragmentation is due only to gravity, can fulfill all the observational constraints on star formation and predict a large number of substellar objects. On the other hand, recent numerical simulations of compressible turbulence, in particular in super-Alfv\'enic conditions, seem to reproduce both qualitatively and quantitatively the stellar and substellar IMF and thus provide an appealing theoretical foundation. In this picture, star formation is induced by the dissipation of large-scale turbulence to smaller scales through radiative MHD shocks, producing filamentary structures. These shocks produce local nonequilibrium structures with large density contrasts, which collapse eventually in gravitationally bound objects under the combined influence of turbulence and gravity. The concept of a single Jeans mass is replaced by a distribution of local Jeans masses, representative of the lognormal probability density function of the turbulent gas. Objects below the mean thermal Jeans mass still have a possibility to collapse, although with a decreasing probability. The page charges for this Review were partially covered by a generous gift from a PASP supporter.},
  keywords = {galaxies: luminosity function,Invited Reviews,mass function},
  file = {/Users/chahah/Zotero/storage/85R99S8V/Chabrier - 2003 - Galactic Stellar and Substellar Initial Mass Funct.pdf}
}

@article{conroy2009,
  title = {The Propagation of Uncertainties in Stellar Population Synthesis Modeling {{I}}: {{The}} Relevance of Uncertain Aspects of Stellar Evolution and the {{IMF}} to the Derived Physical Properties of Galaxies},
  shorttitle = {The Propagation of Uncertainties in Stellar Population Synthesis Modeling {{I}}},
  author = {Conroy, Charlie and Gunn, James E. and White, Martin},
  year = {2009},
  month = jul,
  journal = {The Astrophysical Journal},
  volume = {699},
  number = {1},
  eprint = {0809.4261},
  pages = {486--506},
  issn = {0004-637X, 1538-4357},
  doi = {10.1088/0004-637X/699/1/486},
  urldate = {2019-01-22},
  abstract = {The stellar masses, mean ages, metallicities, and star formation histories of galaxies are now commonly estimated via stellar population synthesis (SPS) techniques. SPS relies on stellar evolution calculations from the main sequence to stellar death, stellar spectral libraries, phenomenological dust models, and stellar initial mass functions (IMFs). The present work is the first in a series that explores the impact of uncertainties in key phases of stellar evolution and the IMF on the derived physical properties of galaxies and the expected luminosity evolution for a passively evolving set of stars. A Monte-Carlo Markov-Chain approach is taken to fit near-UV through near-IR photometry of a representative sample of low- and high-redshift galaxies with this new SPS model. Significant results include the following: 1) including uncertainties in stellar evolution, stellar masses at z\textasciitilde 0 carry errors of \textasciitilde 0.3 dex at 95\% CL with little dependence on luminosity or color, while at z\textasciitilde 2, the masses of bright red galaxies are uncertain at the \textasciitilde 0.6 dex level; 2) either current stellar evolution models, current observational stellar libraries, or both, do not adequately characterize the metallicity-dependence of the thermally-pulsating asymptotic giant branch phase; 3) conservative estimates on the uncertainty of the slope of the IMF in the solar neighborhood imply that luminosity evolution per unit redshift is uncertain at the \textasciitilde 0.4 mag level in the K-band, which is a substantial source of uncertainty for interpreting the evolution of galaxy populations across time; 4) The more plausible assumption of a distribution of stellar metallicities, rather than a fixed value as is usually assumed, can have significant effects on the interpretation of colors blueward of the V-band. (ABRIDGED)},
  archiveprefix = {arxiv},
  keywords = {Astrophysics},
  file = {/Users/chahah/Zotero/storage/DKY5FF9W/Conroy et al. - 2009 - The propagation of uncertainties in stellar popula.pdf;/Users/chahah/Zotero/storage/N2IGMZ62/0809.html}
}

@article{conroy2010b,
  title = {The Propagation of Uncertainties in Stellar Population Synthesis Modeling {{II}}: {{The}} Challenge of Comparing Galaxy Evolution Models to Observations},
  shorttitle = {The Propagation of Uncertainties in Stellar Population Synthesis Modeling {{II}}},
  author = {Conroy, Charlie and White, Martin and Gunn, James E.},
  year = {2010},
  month = jan,
  journal = {The Astrophysical Journal},
  volume = {708},
  number = {1},
  eprint = {0904.0002},
  pages = {58--70},
  issn = {0004-637X, 1538-4357},
  doi = {10.1088/0004-637X/708/1/58},
  urldate = {2019-01-22},
  abstract = {Models for the formation and evolution of galaxies readily predict physical properties such as the star formation rates, metal enrichment histories, and, increasingly, gas and dust content of synthetic galaxies. Such predictions are frequently compared to the spectral energy distributions of observed galaxies via the stellar population synthesis (SPS) technique. Substantial uncertainties in SPS exist, and yet their relevance to the task of comparing galaxy evolution models to observations has received little attention. In the present work we begin to address this issue by investigating the importance of uncertainties in stellar evolution, the initial stellar mass function (IMF), and dust and interstellar medium (ISM) properties on the translation from models to observations. We demonstrate that these uncertainties translate into substantial uncertainties in the ultraviolet, optical, and near-infrared colors of synthetic galaxies. Aspects that carry significant uncertainties include the logarithmic slope of the IMF above 1 Msun, dust attenuation law, molecular cloud disruption timescale, clumpiness of the ISM, fraction of unobscured starlight, and treatment of advanced stages of stellar evolution including blue stragglers, the horizontal branch, and the thermally-pulsating asymptotic giant branch. The interpretation of the resulting uncertainties in the derived colors is highly non-trivial because many of the uncertainties are likely systematic, and possibly correlated with the physical properties of galaxies. We therefore urge caution when comparing models to observations.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics},
  file = {/Users/chahah/Zotero/storage/N5XIUVIA/Conroy et al. - 2010 - The propagation of uncertainties in stellar popula.pdf;/Users/chahah/Zotero/storage/ASML8QBU/0904.html}
}

@article{conroy2010c,
  title = {The {{Propagation}} of {{Uncertainties}} in {{Stellar Population Synthesis Modeling}}. {{III}}. {{Model Calibration}}, {{Comparison}}, and {{Evaluation}}},
  author = {Conroy, Charlie and Gunn, James E.},
  year = {2010},
  month = apr,
  journal = {The Astrophysical Journal},
  volume = {712},
  pages = {833--857},
  issn = {0004-637X},
  doi = {10.1088/0004-637X/712/2/833},
  urldate = {2021-06-29},
  abstract = {Stellar population synthesis (SPS) provides the link between the stellar and dust content of galaxies and their observed spectral energy distributions. In the present work, we perform a comprehensive calibration of our own flexible SPS (FSPS) model against a suite of data. These data include ultraviolet, optical, and near-IR photometry, surface brightness fluctuations, and integrated spectra of star clusters in the Magellanic Clouds (MCs), M87, M31, and the Milky Way (MW), and photometry and spectral indices of both quiescent and post-starburst galaxies at z \textasciitilde{} 0. Several public SPS models are intercompared, including the models of Bruzual \& Charlot (BC03), Maraston (M05), and FSPS. The relative strengths and weaknesses of these models are evaluated, with the following conclusions: (1) the FSPS and BC03 models compare favorably with MC data at all ages, whereas M05 colors are too red and the age dependence is incorrect; (2) all models yield similar optical and near-IR colors for old metal-poor systems, and yet they all provide poor fits to the integrated J - K and V - K colors of both MW and M31 star clusters; (3) FSPS is able to fit all of the ultraviolet data because both the post-asymptotic giant branch (post-AGB) and horizontal branch evolutionary phases are handled flexibly, while the BC03 and M05 models fail in the far-UV, and both far- and near-UV, respectively; (4) all models predict ugr colors too red, D n 4000 strengths too strong, and H{$\delta$} A strengths too weak compared to massive red sequence galaxies, under the assumption that such galaxies are composed solely of old metal-rich stars; and (5) FSPS and, to a lesser extent, BC03 can reproduce the optical and near-IR colors of post-starburst galaxies, while M05 cannot. Reasons for these discrepancies are explored. The failure at predicting the ugr colors, D n 4000, and H{$\delta$} A strengths can be explained by some combination of a minority population of metal-poor stars, young stars, blue straggler and/or blue horizontal branch (HB) stars, but not by appealing to inadequacies in either theoretical stellar atmospheres or canonical evolutionary phases (e.g., the main-sequence turnoff). The different model predictions in the near-IR for intermediate age systems are due to different treatments of the thermally pulsating asymptotic giant branch stellar evolutionary phase. We emphasize that due to a lack of calibrating star cluster data in regions of the metallicity-age plane relevant for galaxies, all of these models continue to suffer from serious uncertainties that are difficult to quantify.},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,galaxies: evolution,galaxies: stellar content,stars: evolution},
  file = {/Users/chahah/Zotero/storage/8N5ZRABN/Conroy and Gunn - 2010 - The Propagation of Uncertainties in Stellar Popula.pdf;/Users/chahah/Zotero/storage/PL7MH2II/abstract.html}
}

@article{dax2021,
  title = {Real-{{Time Gravitational Wave Science}} with {{Neural Posterior Estimation}}},
  author = {Dax, Maximilian and Green, Stephen R. and Gair, Jonathan and Macke, Jakob H. and Buonanno, Alessandra and Sch{\"o}lkopf, Bernhard},
  year = {2021},
  month = dec,
  journal = {Physical Review Letters},
  volume = {127},
  pages = {241103},
  issn = {0031-9007},
  doi = {10.1103/PhysRevLett.127.241103},
  urldate = {2022-08-22},
  abstract = {We demonstrate unprecedented accuracy for rapid gravitational wave parameter estimation with deep learning. Using neural networks as surrogates for Bayesian posterior distributions, we analyze eight gravitational wave events from the first LIGO-Virgo Gravitational-Wave Transient Catalog and find very close quantitative agreement with standard inference codes, but with inference times reduced from O (day ) to 20 s per event. Our networks are trained using simulated data, including an estimate of the detector noise characteristics near the event. This encodes the signal and noise models within millions of neural-network parameters and enables inference for any observed data consistent with the training distribution, accounting for noise nonstationarity from event to event. Our algorithm\textemdash called "DINGO"\textemdash sets a new standard in fast and accurate inference of physical parameters of detected gravitational wave events, which should enable real-time data analysis without sacrificing accuracy.},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,General Relativity and Quantum Cosmology},
  annotation = {ADS Bibcode: 2021PhRvL.127x1103D},
  file = {/Users/chahah/Zotero/storage/LZI4XGZQ/Dax et al. - 2021 - Real-Time Gravitational Wave Science with Neural P.pdf}
}

@article{dolag2009,
  title = {Substructures in Hydrodynamical Cluster Simulations},
  author = {Dolag, K. and Borgani, S. and Murante, G. and Springel, V.},
  year = {2009},
  month = oct,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {399},
  pages = {497--514},
  issn = {0035-8711},
  doi = {10.1111/j.1365-2966.2009.15034.x},
  urldate = {2023-05-04},
  abstract = {The abundance and structure of dark matter subhaloes have been analysed extensively in recent studies of dark-matter-only simulations, but comparatively little is known about the impact of baryonic physics on halo substructures. We here extend the SUBFIND algorithm for substructure identification such that it can be reliably applied to dissipative hydrodynamical simulations that include star formation. This allows, in particular, the identification of galaxies as substructures in simulations of clusters of galaxies and a determination of their content of gravitationally bound stars, dark matter and hot and cold gas. Using a large set of cosmological cluster simulations, we present a detailed analysis of halo substructures in hydrodynamical simulations of galaxy clusters, focusing in particular on the influence both of radiative and non-radiative gas physics and of non-standard physics such as thermal conduction and feedback by galactic outflows. We also examine the impact of numerical nuisance parameters such as artificial viscosity parameterizations. We find that diffuse hot gas is efficiently stripped from subhaloes when they enter the highly pressurized cluster atmosphere. This has the effect of decreasing the subhalo mass function relative to a corresponding dark-matter-only simulation. These effects are mitigated in radiative runs, where baryons condense in the central subhalo regions and form compact stellar cores. However, in all cases, only a very small fraction, of the order of one per cent, of subhaloes within the cluster virial radii preserve a gravitationally bound hot gaseous atmosphere. The fraction of mass contributed by gas in subhaloes is found to increase with the cluster-centric distance. Interestingly, this trend extends well beyond the virial radii, thus showing that galaxies feel the environment of the pressurized cluster gas over fairly large distances. The compact stellar cores (i.e. galaxies) are generally more resistant against tidal disruption than pure dark matter subhaloes. Still, the fraction of star-dominated substructures within our simulated clusters is only \textasciitilde 10 per cent. We expect that the finite resolution in our simulations makes the galaxies overly susceptible to tidal disruption, hence the above fraction of star-dominated galaxies should represent a lower limit for the actual fraction of galaxies surviving the disruption of their host dark matter subhalo.},
  keywords = {Astrophysics,cosmology: theory,galaxies: clusters: general,galaxies: evolution,hydrodynamics,methods: numerical},
  annotation = {ADS Bibcode: 2009MNRAS.399..497D},
  file = {/Users/chahah/Zotero/storage/UI2VX2QP/Dolag et al. - 2009 - Substructures in hydrodynamical cluster simulation.pdf}
}

@misc{greenberg2019,
  title = {Automatic {{Posterior Transformation}} for {{Likelihood-Free Inference}}},
  author = {Greenberg, David S. and Nonnenmacher, Marcel and Macke, Jakob H.},
  year = {2019},
  month = may,
  journal = {arXiv e-prints},
  urldate = {2021-12-14},
  abstract = {How can one perform Bayesian inference on stochastic simulators with intractable likelihoods? A recent approach is to learn the posterior from adaptively proposed simulations using neural network-based conditional density estimators. However, existing methods are limited to a narrow range of proposal distributions or require importance weighting that can limit performance in practice. Here we present automatic posterior transformation (APT), a new sequential neural posterior estimation method for simulation-based inference. APT can modify the posterior estimate using arbitrary, dynamically updated proposals, and is compatible with powerful flow-based density estimators. It is more flexible, scalable and efficient than previous simulation-based inference techniques. APT can operate directly on high-dimensional time series and image data, opening up new applications for likelihood-free inference.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {ADS Bibcode: 2019arXiv190507488G},
  file = {/Users/chahah/Zotero/storage/YR94IYTS/Greenberg et al. - 2019 - Automatic Posterior Transformation for Likelihood-.pdf}
}

@article{hahn2017b,
  title = {Approximate {{Bayesian Computation}} in {{Large Scale Structure}}: Constraining the Galaxy-Halo Connection},
  shorttitle = {Approximate {{Bayesian Computation}} in {{Large Scale Structure}}},
  author = {Hahn, ChangHoon and Vakili, Mohammadjavad and Walsh, Kilian and Hearin, Andrew P. and Hogg, David W. and Campbell, Duncan},
  year = {2017},
  month = aug,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {469},
  number = {3},
  eprint = {1607.01782},
  pages = {2791--2805},
  issn = {0035-8711, 1365-2966},
  doi = {10.1093/mnras/stx894},
  abstract = {Standard approaches to Bayesian parameter inference in large scale structure assume a Gaussian functional form (chi-squared form) for the likelihood. This assumption, in detail, cannot be correct. Likelihood free inferences such as Approximate Bayesian Computation (ABC) relax these restrictions and make inference possible without making any assumptions on the likelihood. Instead ABC relies on a forward generative model of the data and a metric for measuring the distance between the model and data. In this work, we demonstrate that ABC is feasible for LSS parameter inference by using it to constrain parameters of the halo occupation distribution (HOD) model for populating dark matter halos with galaxies. Using specific implementation of ABC supplemented with Population Monte Carlo importance sampling, a generative forward model using HOD, and a distance metric based on galaxy number density, two-point correlation function, and galaxy group multiplicity function, we constrain the HOD parameters of mock observation generated from selected "true" HOD parameters. The parameter constraints we obtain from ABC are consistent with the "true" HOD parameters, demonstrating that ABC can be reliably used for parameter inference in LSS. Furthermore, we compare our ABC constraints to constraints we obtain using a pseudo-likelihood function of Gaussian form with MCMC and find consistent HOD parameter constraints. Ultimately our results suggest that ABC can and should be applied in parameter inference for LSS analyses.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics},
  file = {/Users/chahah/Zotero/storage/7PC9B39G/Hahn et al. - 2017 - Approximate Bayesian Computation in Large Scale St.pdf;/Users/chahah/Zotero/storage/HPNZWAZN/1607.html}
}

@article{hahn2019c,
  title = {Likelihood Non-{{Gaussianity}} in Large-Scale Structure Analyses},
  author = {Hahn, ChangHoon and Beutler, Florian and Sinha, Manodeep and Berlind, Andreas and Ho, Shirley and Hogg, David W.},
  year = {2019},
  month = may,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {485},
  pages = {2956--2969},
  issn = {0035-8711},
  doi = {10.1093/mnras/stz558},
  urldate = {2019-04-09},
  abstract = {Standard present-day large-scale structure (LSS) analyses make a major assumption in their Bayesian parameter inference - that the likelihood has a Gaussian form. For summary statistics currently used in LSS, this assumption, even if the underlying density field is Gaussian, cannot be correct in detail. We investigate the impact of this assumption on two recent LSS analyses: the Beutler et al. power spectrum multipole (P{$\mathscr{l}$}) analysis and the Sinha et al. group multiplicity function ({$\zeta$}) analysis. Using non-parametric divergence estimators on mock catalogues originally constructed for covariance matrix estimation, we identify significant non-Gaussianity in both the P{$\mathscr{l}$} and {$\zeta$} likelihoods. We then use Gaussian mixture density estimation and independent component analysis on the same mocks to construct likelihood estimates that approximate the true likelihood better than the Gaussian pseudo-likelihood. Using these likelihood estimates, we accurately estimate the true posterior probability distribution of the Beutler et al. and Sinha et al. parameters. Likelihood non-Gaussianity shifts the f{$\sigma$}8 constraint by -0.44{$\sigma$}, but otherwise does not significantly impact the overall parameter constraints of Beutler et al. For the {$\zeta$} analysis, using the pseudo-likelihood significantly underestimates the uncertainties and biases the constraints of the Sinha et al. halo occupation parameters. For log M\_1 and {$\alpha$}, the posteriors are shifted by +0.43{$\sigma$} and -0.51{$\sigma$} and broadened by 42\{\{ per cent\}\} and 66\{\{ per cent\}\}, respectively. The divergence and likelihood estimation methods we present provide a straightforward framework for quantifying the impact of likelihood non-Gaussianity and deriving more accurate parameter constraints.},
  keywords = {cosmological parameters,cosmology: observations,galaxies: statistics,large-scale structure of Universe,methods: data analysis,methods: statistical},
  file = {/Users/chahah/Zotero/storage/3PJRJ6RV/Hahn et al. - 2019 - Likelihood non-Gaussianity in large-scale structur.pdf}
}

@misc{hahn2022a,
  title = {Accelerated {{Bayesian SED Modeling}} Using {{Amortized Neural Posterior Estimation}}},
  author = {Hahn, ChangHoon and Melchior, Peter},
  year = {2022},
  month = mar,
  journal = {arXiv e-prints},
  urldate = {2022-03-24},
  abstract = {State-of-the-art spectral energy distribution (SED) analyses use a Bayesian framework to infer the physical properties of galaxies from observed photometry or spectra. They require sampling from a high-dimensional space of SED model parameters and take \${$>$}10-100\$ CPU hours per galaxy, which renders them practically infeasible for analyzing the \$billions\$ of galaxies that will be observed by upcoming galaxy surveys (\$e.g.\$ DESI, PFS, Rubin, Webb, and Roman). In this work, we present an alternative scalable approach to rigorous Bayesian inference using Amortized Neural Posterior Estimation (ANPE). ANPE is a simulation-based inference method that employs neural networks to estimate the posterior probability distribution over the full range of observations. Once trained, it requires no additional model evaluations to estimate the posterior. We present, and publicly release, \$\{\textbackslash rm SED\}\{flow\}\$, an ANPE method to produce posteriors of the recent Hahn et al. (2022) SED model from optical photometry. \$\{\textbackslash rm SED\}\{flow\}\$ takes \$\{\textbackslash sim\}1\$ \$second\textasciitilde per\textasciitilde galaxy\$ to obtain the posterior distributions of 12 model parameters, all of which are in excellent agreement with traditional Markov Chain Monte Carlo sampling results. We also apply \$\{\textbackslash rm SED\}\{flow\}\$ to 33,884 galaxies in the NASA-Sloan Atlas and publicly release their posteriors: see https://changhoonhahn.github.io/SEDflow.},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Statistics - Machine Learning},
  annotation = {ADS Bibcode: 2022arXiv220307391H},
  file = {/Users/chahah/Zotero/storage/ZRYGFVV3/Hahn and Melchior - 2022 - Accelerated Bayesian SED Modeling using Amortized .pdf}
}

@misc{hahn2022d,
  title = {\$\{\textbackslash rm \vphantom\}{{S}}\{\textbackslash scriptsize \vphantom\}{{IM}}\vphantom\{\}{{BIG}}\vphantom\{\}\$: {{A Forward Modeling Approach To Analyzing Galaxy Clustering}}},
  shorttitle = {\$\{\textbackslash rm \vphantom\}{{S}}\{\textbackslash scriptsize \vphantom\}{{IM}}\vphantom\{\}{{BIG}}\vphantom\{\}\$},
  author = {Hahn, ChangHoon and Eickenberg, Michael and Ho, Shirley and Hou, Jiamin and Lemos, Pablo and Massara, Elena and Modi, Chirag and Moradinezhad Dizgah, Azadeh and {R{\'e}galdo-Saint Blancard}, Bruno and Abidi, Muntazir M.},
  year = {2022},
  month = nov,
  journal = {arXiv e-prints},
  urldate = {2022-11-03},
  abstract = {We present the first-ever cosmological constraints from a simulation-based inference (SBI) analysis of galaxy clustering from the new \$\{\textbackslash rm S\{\textbackslash scriptsize IM\}BIG\}\$ forward modeling framework. \$\{\textbackslash rm S\{\textbackslash scriptsize IM\}BIG\}\$ leverages the predictive power of high-fidelity simulations and provides an inference framework that can extract cosmological information on small non-linear scales, inaccessible with standard analyses. In this work, we apply \$\{\textbackslash rm S\{\textbackslash scriptsize IM\}BIG\}\$ to the BOSS CMASS galaxy sample and analyze the power spectrum, \$P\_\textbackslash ell(k)\$, to \$k\_\{\textbackslash rm max\}=0.5\textbackslash,h/\{\textbackslash rm Mpc\}\$. We construct 20,000 simulated galaxy samples using our forward model, which is based on high-resolution \$\{\textbackslash rm Q\{\textbackslash scriptsize UIJOTE\}\}\$ \$N\$-body simulations and includes detailed survey realism for a more complete treatment of observational systematics. We then conduct SBI by training normalizing flows using the simulated samples and infer the posterior distribution of \$\textbackslash Lambda\$CDM cosmological parameters: \$\textbackslash Omega\_m, \textbackslash Omega\_b, h, n\_s, \textbackslash sigma\_8\$. We derive significant constraints on \$\textbackslash Omega\_m\$ and \$\textbackslash sigma\_8\$, which are consistent with previous works. Our constraints on \$\textbackslash sigma\_8\$ are \$27\textbackslash\%\$ more precise than standard analyses. This improvement is equivalent to the statistical gain expected from analyzing a galaxy sample that is \$\textbackslash sim60\textbackslash\%\$ larger than CMASS with standard methods. It results from additional cosmological information on non-linear scales beyond the limit of current analytic models, \$k {$>$} 0.25\textbackslash,h/\{\textbackslash rm Mpc\}\$. While we focus on \$P\_\textbackslash ell\$ in this work for validation and comparison to the literature, \$\{\textbackslash rm S\{\textbackslash scriptsize IM\}BIG\}\$ provides a framework for analyzing galaxy clustering using any summary statistic. We expect further improvements on cosmological constraints from subsequent \$\{\textbackslash rm S\{\textbackslash scriptsize IM\}BIG\}\$ analyses of summary statistics beyond \$P\_\textbackslash ell\$.},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics},
  annotation = {ADS Bibcode: 2022arXiv221100723H},
  file = {/Users/chahah/Zotero/storage/2XLAHAAQ/Hahn et al. - 2022 - $ rm S scriptsize IM BIG $ A Forward Modeling A.pdf}
}

@article{hahn2023,
  title = {{{SIMBIG}}: Mock Challenge for a Forward Modeling Approach to Galaxy Clustering},
  shorttitle = {{{SIMBIG}}},
  author = {Hahn, ChangHoon and Eickenberg, Michael and Ho, Shirley and Hou, Jiamin and Lemos, Pablo and Massara, Elena and Modi, Chirag and Moradinezhad Dizgah, Azadeh and {R{\'e}galdo-Saint Blancard}, Bruno and Abidi, Muntazir M.},
  year = {2023},
  month = apr,
  journal = {Journal of Cosmology and Astroparticle Physics},
  volume = {2023},
  pages = {010},
  issn = {1475-7516},
  doi = {10.1088/1475-7516/2023/04/010},
  urldate = {2023-04-12},
  abstract = {Simulation-Based Inference of Galaxies (SIMBIG) is a forward modeling framework for analyzing galaxy clustering using simulation-based inference. In this work, we present the SIMBIG forward model, which is designed to match the observed SDSS-III BOSS CMASS galaxy sample. The forward model is based on high-resolution QUIJOTE N-body simulations and a flexible halo occupation model. It includes full survey realism and models observational systematics such as angular masking and fiber collisions. We present the "mock challenge" for validating the accuracy of posteriors inferred from SIMBIG using a suite of 1,500 test simulations constructed using forward models with a different N-body simulation, halo finder, and halo occupation prescription. As a demonstration of SIMBIG, we analyze the power spectrum multipoles out to k max = 0.5 h/Mpc and infer the posterior of {$\Lambda$}CDM cosmological and halo occupation parameters. Based on the mock challenge, we find that our constraints on {$\Omega$} m and {$\sigma$} 8 are unbiased, but conservative. Hence, the mock challenge demonstrates that SIMBIG provides a robust framework for inferring cosmological parameters from galaxy clustering on non-linear scales and a complete framework for handling observational systematics. In subsequent work, we will use SIMBIG to analyze summary statistics beyond the power spectrum including the bispectrum, marked power spectrum, skew spectrum, wavelet statistics, and field-level statistics.},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,cosmological parameters from LSS,cosmological simulations,Machine learning,redshift surveys},
  annotation = {ADS Bibcode: 2023JCAP...04..010H},
  file = {/Users/chahah/Zotero/storage/RGGV9DP3/Hahn et al. - 2023 - SIMBIG mock challenge for a forward modeling appr.pdf}
}

@article{kingma2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  journal = {arXiv:1412.6980 [cs]},
  eprint = {1412.6980},
  primaryclass = {cs},
  urldate = {2021-12-28},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/chahah/Zotero/storage/MI6H6F53/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/Users/chahah/Zotero/storage/MNT2L3WN/1412.html}
}

@misc{lemos2023,
  title = {Sampling-{{Based Accuracy Testing}} of {{Posterior Estimators}} for {{General Inference}}},
  author = {Lemos, Pablo and Coogan, Adam and Hezaveh, Yashar and {Perreault-Levasseur}, Laurence},
  year = {2023},
  month = feb,
  journal = {arXiv.org},
  urldate = {2023-05-05},
  abstract = {Parameter inference, i.e. inferring the posterior distribution of the parameters of a statistical model given some data, is a central problem to many scientific disciplines. Posterior inference with generative models is an alternative to methods such as Markov Chain Monte Carlo, both for likelihood-based and simulation-based inference. However, assessing the accuracy of posteriors encoded in generative models is not straightforward. In this paper, we introduce `distance to random point' (DRP) coverage testing as a method to estimate coverage probabilities of generative posterior estimators. Our method differs from previously-existing coverage-based methods, which require posterior evaluations. We prove that our approach is necessary and sufficient to show that a posterior estimator is optimal. We demonstrate the method on a variety of synthetic examples, and show that DRP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect non-optimal inferences in cases where existing methods fail.},
  howpublished = {https://arxiv.org/abs/2302.03026v1},
  langid = {english},
  file = {/Users/chahah/Zotero/storage/N2F2R6UX/Lemos et al. - 2023 - Sampling-Based Accuracy Testing of Posterior Estim.pdf}
}

@article{nelson2018,
  title = {First Results from the {{IllustrisTNG}} Simulations: The Galaxy Colour Bimodality},
  shorttitle = {First Results from the {{IllustrisTNG}} Simulations},
  author = {Nelson, Dylan and Pillepich, Annalisa and Springel, Volker and Weinberger, Rainer and Hernquist, Lars and Pakmor, R{\"u}diger and Genel, Shy and Torrey, Paul and Vogelsberger, Mark and Kauffmann, Guinevere and Marinacci, Federico and Naiman, Jill},
  year = {2018},
  month = mar,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {475},
  pages = {624--647},
  issn = {0035-8711},
  doi = {10.1093/mnras/stx3040},
  urldate = {2020-07-10},
  abstract = {We introduce the first two simulations of the IllustrisTNG project, a next generation of cosmological magnetohydrodynamical simulations, focusing on the optical colours of galaxies. We explore TNG100, a rerun of the original Illustris box, and TNG300, which includes 2 \texttimes{} 25003 resolution elements in a volume 20 times larger. Here, we present first results on the galaxy colour bimodality at low redshift. Accounting for the attenuation of stellar light by dust, we compare the simulated (g - r) colours of 109 {$<$} M{$\star$}/M{$\odot$} {$<$} 1012.5 galaxies to the observed distribution from the Sloan Digital Sky Survey. We find a striking improvement with respect to the original Illustris simulation, as well as excellent quantitative agreement with the observations, with a sharp transition in median colour from blue to red at a characteristic M{$\star$} {$\sim$} 1010.5 M{$\odot$}. Investigating the build-up of the colour-mass plane and the formation of the red sequence, we demonstrate that the primary driver of galaxy colour transition is supermassive black hole feedback in its low accretion state. Across the entire population the median colour transition time-scale {$\Delta$}tgreen is {$\sim$}1.6 Gyr, a value which drops for increasingly massive galaxies. We find signatures of the physical process of quenching: at fixed stellar mass, redder galaxies have lower star formation rates, gas fractions, and gas metallicities; their stellar populations are also older and their large-scale interstellar magnetic fields weaker than in bluer galaxies. Finally, we measure the amount of stellar mass growth on the red sequence. Galaxies with M{$\star$} {$>$} 1011 M{$\odot$} which redden at z {$<$} 1 accumulate on average {$\sim$}25 per cent of their final z = 0 mass post-reddening; at the same time, {$\sim$}18 per cent of such massive galaxies acquire half or more of their final stellar mass while on the red sequence.},
  keywords = {galaxies: evolution,galaxies: formation},
  file = {/Users/chahah/Zotero/storage/WGG84ZKD/Nelson et al. - 2018 - First results from the IllustrisTNG simulations t.pdf}
}

@article{papamakarios2017,
  title = {Masked {{Autoregressive Flow}} for {{Density Estimation}}},
  author = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  year = {2017},
  month = may,
  journal = {arXiv e-prints},
  volume = {1705},
  pages = {arXiv:1705.07057},
  urldate = {2021-06-02},
  abstract = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/chahah/Zotero/storage/VCZVEKYM/Papamakarios et al. - 2017 - Masked Autoregressive Flow for Density Estimation.pdf}
}

@article{springel2001,
  title = {Populating a Cluster of Galaxies - {{I}}. {{Results}} at [Formmu2]Z=0},
  author = {Springel, Volker and White, Simon D. M. and Tormen, Giuseppe and Kauffmann, Guinevere},
  year = {2001},
  month = dec,
  journal = {Monthly Notices of the Royal Astronomical Society},
  volume = {328},
  pages = {726--750},
  issn = {0035-8711},
  doi = {10.1046/j.1365-8711.2001.04912.x},
  urldate = {2018-05-09},
  abstract = {We simulate the assembly of a massive rich cluster and the formation of its constituent galaxies in a flat, low-density universe. Our most accurate model follows the collapse, the star formation history and the orbital motion of all galaxies more luminous than the Fornax dwarf spheroidal, while dark halo structure is tracked consistently throughout the cluster for all galaxies more luminous than the SMC. Within its virial radius this model contains about 2\texttimes 107 dark matter particles and almost 5000 distinct dynamically resolved galaxies. Simulations of this same cluster at a variety of resolutions allow us to check explicitly for numerical convergence both of the dark matter structures produced by our new parallel N-body and substructure identification codes, and of the galaxy populations produced by the phenomenological models we use to follow cooling, star formation, feedback and stellar aging. This baryonic modelling is tuned so that our simulations reproduce the observed properties of isolated spirals outside clusters. Without further parameter adjustment our simulations then produce a luminosity function, a mass-to-light ratio, luminosity, number and velocity dispersion profiles, and a morphology-radius relation which are similar to those observed in real clusters. In particular, since our simulations follow galaxy merging explicitly, we can demonstrate that it accounts quantitatively for the observed cluster population of bulges and elliptical galaxies.},
  keywords = {DARK MATTER,GALAXIES: CLUSTERS: GENERAL,GALAXIES: FORMATION},
  file = {/Users/chahah/Zotero/storage/VQ6FG7CT/Springel et al. - 2001 - Populating a cluster of galaxies - I. Results at [.pdf}
}

@article{tabak2010,
  title = {Density Estimation by Dual Ascent of the Log-Likelihood},
  author = {Tabak, Esteban G. and {Vanden-Eijnden}, Eric},
  year = {2010},
  month = mar,
  journal = {Communications in Mathematical Sciences},
  volume = {8},
  number = {1},
  pages = {217--233},
  publisher = {{International Press of Boston}},
  issn = {1945-0796},
  doi = {10.4310/CMS.2010.v8.n1.a11},
  urldate = {2021-12-27},
  abstract = {International Press of Boston - publishers of scholarly mathematical and scientific journals and books},
  langid = {english},
  file = {/Users/chahah/Zotero/storage/EQETEFI4/Tabak and Vanden-Eijnden - 2010 - Density estimation by dual ascent of the log-likel.pdf;/Users/chahah/Zotero/storage/VKABWVKF/a011.html}
}

@article{tabak2013,
  title = {A {{Family}} of {{Nonparametric Density Estimation Algorithms}}},
  author = {Tabak, E. G. and Turner, Cristina V.},
  year = {2013},
  journal = {Communications on Pure and Applied Mathematics},
  volume = {66},
  number = {2},
  pages = {145--164},
  issn = {1097-0312},
  doi = {10.1002/cpa.21423},
  urldate = {2021-12-27},
  abstract = {A new methodology for density estimation is proposed. The methodology, which builds on the one developed by Tabak and Vanden-Eijnden, normalizes the data points through the composition of simple maps. The parameters of each map are determined through the maximization of a local quadratic approximation to the log-likelihood. Various candidates for the elementary maps of each step are proposed; criteria for choosing one includes robustness, computational simplicity, and good behavior in high-dimensional settings. A good choice is that of localized radial expansions, which depend on a single parameter: all the complexity of arbitrary, possibly convoluted probability densities can be built through the composition of such simple maps. \textcopyright{} 2012 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/Users/chahah/Zotero/storage/DQBBZHA3/Tabak and Turner - 2013 - A Family of Nonparametric Density Estimation Algor.pdf;/Users/chahah/Zotero/storage/6PGKDQCR/cpa.html}
}

@article{tejero-cantero2020,
  title = {Sbi: {{A}} Toolkit for Simulation-Based Inference},
  shorttitle = {Sbi},
  author = {{Tejero-Cantero}, Alvaro and Boelts, Jan and Deistler, Michael and Lueckmann, Jan-Matthis and Durkan, Conor and Gon{\c c}alves, Pedro J. and Greenberg, David S. and Macke, Jakob H.},
  year = {2020},
  month = aug,
  journal = {Journal of Open Source Software},
  volume = {5},
  number = {52},
  pages = {2505},
  issn = {2475-9066},
  doi = {10.21105/joss.02505},
  urldate = {2021-12-03},
  abstract = {Tejero-Cantero et al., (2020). sbi: A toolkit for simulation-based inference. Journal of Open Source Software, 5(52), 2505, https://doi.org/10.21105/joss.02505},
  langid = {english},
  file = {/Users/chahah/Zotero/storage/W7ZTXV3T/Tejero-Cantero et al. - 2020 - sbi A toolkit for simulation-based inference.pdf;/Users/chahah/Zotero/storage/CNSAGFZM/joss.html}
}

@article{villaescusa-navarro2021,
  title = {The {{CAMELS}} Project: {{Cosmology}} and {{Astrophysics}} with {{MachinE Learning Simulations}}},
  shorttitle = {The {{CAMELS}} Project},
  author = {{Villaescusa-Navarro}, Francisco and {Angl{\'e}s-Alc{\'a}zar}, Daniel and Genel, Shy and Spergel, David N. and Somerville, Rachel S. and Dave, Romeel and Pillepich, Annalisa and Hernquist, Lars and Nelson, Dylan and Torrey, Paul and Narayanan, Desika and Li, Yin and Philcox, Oliver and La Torre, Valentina and Delgado, Ana Maria and Ho, Shirley and Hassan, Sultan and Burkhart, Blakesley and Wadekar, Digvijay and Battaglia, Nicholas and Contardo, Gabriella and Bryan, Greg L.},
  year = {2021},
  month = jul,
  journal = {The Astrophysical Journal},
  volume = {915},
  number = {1},
  eprint = {2010.00619},
  pages = {71},
  issn = {0004-637X, 1538-4357},
  doi = {10.3847/1538-4357/abf7ba},
  urldate = {2021-09-08},
  abstract = {We present the Cosmology and Astrophysics with MachinE Learning Simulations --CAMELS-- project. CAMELS is a suite of 4,233 cosmological simulations of \$(25\textasciitilde h\^\{-1\}\{\textbackslash rm Mpc\})\^3\$ volume each: 2,184 state-of-the-art (magneto-)hydrodynamic simulations run with the AREPO and GIZMO codes, employing the same baryonic subgrid physics as the IllustrisTNG and SIMBA simulations, and 2,049 N-body simulations. The goal of the CAMELS project is to provide theory predictions for different observables as a function of cosmology and astrophysics, and it is the largest suite of cosmological (magneto-)hydrodynamic simulations designed to train machine learning algorithms. CAMELS contains thousands of different cosmological and astrophysical models by way of varying \$\textbackslash Omega\_m\$, \$\textbackslash sigma\_8\$, and four parameters controlling stellar and AGN feedback, following the evolution of more than 100 billion particles and fluid elements over a combined volume of \$(400\textasciitilde h\^\{-1\}\{\textbackslash rm Mpc\})\^3\$. We describe the simulations in detail and characterize the large range of conditions represented in terms of the matter power spectrum, cosmic star formation rate density, galaxy stellar mass function, halo baryon fractions, and several galaxy scaling relations. We show that the IllustrisTNG and SIMBA suites produce roughly similar distributions of galaxy properties over the full parameter space but significantly different halo baryon fractions and baryonic effects on the matter power spectrum. This emphasizes the need for marginalizing over baryonic effects to extract the maximum amount of information from cosmological surveys. We illustrate the unique potential of CAMELS using several machine learning applications, including non-linear interpolation, parameter estimation, symbolic regression, data generation with Generative Adversarial Networks (GANs), dimensionality reduction, and anomaly detection.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics},
  file = {/Users/chahah/Zotero/storage/I5VV6DNB/Villaescusa-Navarro et al. - 2021 - The CAMELS project Cosmology and Astrophysics wit.pdf;/Users/chahah/Zotero/storage/EJQGBS7G/2010.html}
}

@article{villaescusa-navarro2022,
  title = {Cosmology with {{One Galaxy}}?},
  author = {{Villaescusa-Navarro}, Francisco and Ding, Jupiter and Genel, Shy and Tonnesen, Stephanie and La Torre, Valentina and Spergel, David N. and Teyssier, Romain and Li, Yin and Heneka, Caroline and Lemos, Pablo and {Angl{\'e}s-Alc{\'a}zar}, Daniel and Nagai, Daisuke and Vogelsberger, Mark},
  year = {2022},
  month = apr,
  journal = {The Astrophysical Journal},
  volume = {929},
  pages = {132},
  issn = {0004-637X},
  doi = {10.3847/1538-4357/ac5d3f},
  urldate = {2022-09-26},
  abstract = {Galaxies can be characterized by many internal properties such as stellar mass, gas metallicity, and star formation rate. We quantify the amount of cosmological and astrophysical information that the internal properties of individual galaxies and their host dark matter halos contain. We train neural networks using hundreds of thousands of galaxies from 2000 state-of-the-art hydrodynamic simulations with different cosmologies and astrophysical models of the CAMELS project to perform likelihood-free inference on the value of the cosmological and astrophysical parameters. We find that knowing the internal properties of a single galaxy allows our models to infer the value of {$\Omega$}m, at fixed {$\Omega$}b, with a \textasciitilde 10\% precision, while no constraint can be placed on {$\sigma$} 8. Our results hold for any type of galaxy, central or satellite, massive or dwarf, at all considered redshifts, z {$\leq$} 3, and they incorporate uncertainties in astrophysics as modeled in CAMELS. However, our models are not robust to changes in subgrid physics due to the large intrinsic differences the two considered models imprint on galaxy properties. We find that the stellar mass, stellar metallicity, and maximum circular velocity are among the most important galaxy properties to determine the value of {$\Omega$}m. We believe that our results can be explained by considering that changes in the value of {$\Omega$}m, or potentially {$\Omega$}b/{$\Omega$}m, affect the dark matter content of galaxies, which leaves a signature in galaxy properties distinct from the one induced by galactic processes. Our results suggest that the low-dimensional manifold hosting galaxy properties provides a tight direct link between cosmology and astrophysics.},
  keywords = {1882,337,595,767,Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Astrostatistics,Cosmological models,Galaxy formation,Hydrodynamical simulations},
  annotation = {ADS Bibcode: 2022ApJ...929..132V},
  file = {/Users/chahah/Zotero/storage/85YRGWZ3/Villaescusa-Navarro et al. - 2022 - Cosmology with One Galaxy.pdf}
}

@article{villaescusa-navarro2022a,
  title = {The {{CAMELS}} Project: Public Data Release},
  shorttitle = {The {{CAMELS}} Project},
  author = {{Villaescusa-Navarro}, Francisco and Genel, Shy and {Angl{\'e}s-Alc{\'a}zar}, Daniel and Perez, Lucia A. and {Villanueva-Domingo}, Pablo and Wadekar, Digvijay and Shao, Helen and Mohammad, Faizan G. and Hassan, Sultan and Moser, Emily and Lau, Erwin T. and Valle, Luis Fernando Machado Poletti and Nicola, Andrina and Thiele, Leander and Jo, Yongseok and Philcox, Oliver H. E. and Oppenheimer, Benjamin D. and Tillman, Megan and Hahn, ChangHoon and Kaushal, Neerav and Pisani, Alice and Gebhardt, Matthew and Delgado, Ana Maria and Caliendo, Joyce and Kreisch, Christina and Wong, Kaze W. K. and Coulton, William R. and Eickenberg, Michael and Parimbelli, Gabriele and Ni, Yueying and Steinwandel, Ulrich P. and La Torre, Valentina and Dave, Romeel and Battaglia, Nicholas and Nagai, Daisuke and Spergel, David N. and Hernquist, Lars and Burkhart, Blakesley and Narayanan, Desika and Wandelt, Benjamin and Somerville, Rachel S. and Bryan, Greg L. and Viel, Matteo and Li, Yin and Irsic, Vid and Kraljic, Katarina and Vogelsberger, Mark},
  year = {2022},
  month = jan,
  journal = {arXiv:2201.01300 [astro-ph]},
  eprint = {2201.01300},
  primaryclass = {astro-ph},
  urldate = {2022-03-10},
  abstract = {The Cosmology and Astrophysics with MachinE Learning Simulations (CAMELS) project was developed to combine cosmology with astrophysics through thousands of cosmological hydrodynamic simulations and machine learning. CAMELS contains 4,233 cosmological simulations, 2,049 N-body and 2,184 state-of-the-art hydrodynamic simulations that sample a vast volume in parameter space. In this paper we present the CAMELS public data release, describing the characteristics of the CAMELS simulations and a variety of data products generated from them, including halo, subhalo, galaxy, and void catalogues, power spectra, bispectra, Lyman-\$\textbackslash alpha\$ spectra, probability distribution functions, halo radial profiles, and X-rays photon lists. We also release over one thousand catalogues that contain billions of galaxies from CAMELS-SAM: a large collection of N-body simulations that have been combined with the Santa Cruz Semi-Analytic Model. We release all the data, comprising more than 350 terabytes and containing 143,922 snapshots, millions of halos, galaxies and summary statistics. We provide further technical details on how to access, download, read, and process the data at \textbackslash url\{https://camels.readthedocs.io\}.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Astrophysics of Galaxies,Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/chahah/Zotero/storage/299Z8BIX/Villaescusa-Navarro et al. - 2022 - The CAMELS project public data release.pdf;/Users/chahah/Zotero/storage/SLW5QXTT/2201.html}
}

@article{weyant2013,
  title = {Likelihood-Free {{Cosmological Inference}} with {{Type Ia Supernovae}}: {{Approximate Bayesian Computation}} for a {{Complete Treatment}} of {{Uncertainty}}},
  shorttitle = {Likelihood-Free {{Cosmological Inference}} with {{Type Ia Supernovae}}},
  author = {Weyant, Anja and Schafer, Chad and {Wood-Vasey}, W. Michael},
  year = {2013},
  month = feb,
  journal = {The Astrophysical Journal},
  volume = {764},
  pages = {116},
  issn = {0004-637X},
  doi = {10.1088/0004-637X/764/2/116},
  urldate = {2018-08-31},
  abstract = {Cosmological inference becomes increasingly difficult when complex  data-generating processes cannot be modeled by simple probability distributions. With the ever-increasing size of data sets in cosmology, there is an increasing burden placed on adequate modeling; systematic errors in the model will dominate where previously these were swamped by statistical errors. For example, Gaussian distributions are an insufficient representation for errors in quantities like photometric redshifts. Likewise, it can be difficult to quantify analytically the distribution of errors that are introduced in complex fitting codes. Without a simple form for these distributions, it becomes difficult to accurately construct a likelihood function for the data as a function of parameters of interest. Approximate Bayesian computation (ABC) provides a means of probing the posterior distribution when direct calculation of a sufficiently accurate likelihood is intractable. ABC allows one to bypass direct calculation of the likelihood but instead relies upon the ability to simulate the forward process that generated the data. These simulations can naturally incorporate priors placed on nuisance parameters, and hence these can be marginalized in a natural way. We present and discuss ABC methods in the context of supernova cosmology using data from the SDSS-II Supernova Survey. Assuming a flat cosmology and constant dark energy equation of state, we demonstrate that ABC can recover an accurate posterior distribution. Finally, we show that ABC can still produce an accurate posterior distribution when we contaminate the sample with Type IIP supernovae.},
  keywords = {cosmological parameters,methods: statistical},
  file = {/Users/chahah/Zotero/storage/PYMFC67P/Weyant et al. - 2013 - Likelihood-free Cosmological Inference with Type I.pdf}
}

@article{wong2020,
  title = {Gravitational Wave Population Inference with Deep Flow-Based Generative Network},
  author = {Wong, Kaze W. K. and Contardo, Gabriella and Ho, Shirley},
  year = {2020},
  month = jun,
  journal = {Physical Review D},
  volume = {101},
  number = {12},
  eprint = {2002.09491},
  pages = {123005},
  issn = {2470-0010, 2470-0029},
  doi = {10.1103/PhysRevD.101.123005},
  urldate = {2021-12-14},
  abstract = {We combine hierarchical Bayesian modeling with a flow-based deep generative network, in order to demonstrate that one can efficiently constraint numerical gravitational wave (GW) population models at a previously intractable complexity. Existing techniques for comparing data to simulation,such as discrete model selection and Gaussian process regression, can only be applied efficiently to moderate-dimension data. This limits the number of observable (e.g. chirp mass, spins.) and hyper-parameters (e.g. common envelope efficiency) one can use in a population inference. In this study, we train a network to emulate a phenomenological model with 6 observables and 4 hyper-parameters, use it to infer the properties of a simulated catalogue and compare the results to the phenomenological model. We find that a 10-layer network can emulate the phenomenological model accurately and efficiently. Our machine enables simulation-based GW population inferences to take on data at a new complexity level.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - High Energy Astrophysical Phenomena,Astrophysics - Instrumentation and Methods for Astrophysics,General Relativity and Quantum Cosmology},
  file = {/Users/chahah/Zotero/storage/MPJKFSWW/Wong et al. - 2020 - Gravitational wave population inference with deep .pdf;/Users/chahah/Zotero/storage/MBS5W4G3/2002.html}
}

@article{zhang2019,
  title = {From {{Dark Matter}} to {{Galaxies}} with {{Convolutional Networks}}},
  author = {Zhang, Xinyue and Wang, Yanfang and Zhang, Wei and Sun, Yueqiu and He, Siyu and Contardo, Gabriella and {Villaescusa-Navarro}, Francisco and Ho, Shirley},
  year = {2019},
  month = feb,
  journal = {arXiv:1902.05965 [astro-ph]},
  eprint = {1902.05965},
  primaryclass = {astro-ph},
  urldate = {2019-02-19},
  abstract = {Cosmological surveys aim at answering fundamental questions about our Universe, including the nature of dark matter or the reason of unexpected accelerated expansion of the Universe. In order to answer these questions, two important ingredients are needed: 1) data from observations and 2) a theoretical model that allows fast comparison between observation and theory. Most of the cosmological surveys observe galaxies, which are very difficult to model theoretically due to the complicated physics involved in their formation and evolution; modeling realistic galaxies over cosmological volumes requires running computationally expensive hydrodynamic simulations that can cost millions of CPU hours. In this paper, we propose to use deep learning to establish a mapping between the 3D galaxy distribution in hydrodynamic simulations and its underlying dark matter distribution. One of the major challenges in this pursuit is the very high sparsity in the predicted galaxy distribution. To this end, we develop a two-phase convolutional neural network architecture to generate fast galaxy catalogues, and compare our results against a standard cosmological technique. We find that our proposed approach either outperforms or is competitive with traditional cosmological techniques. Compared to the common methods used in cosmology, our approach also provides a nice trade-off between time-consumption (comparable to fastest benchmark in the literature) and the quality and accuracy of the predicted simulation. In combination with current and upcoming data from cosmological observations, our method has the potential to answer fundamental questions about our Universe with the highest accuracy.},
  archiveprefix = {arxiv},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Computer Science - Machine Learning},
  file = {/Users/chahah/Zotero/storage/EK3VSXI4/Zhang et al. - 2019 - From Dark Matter to Galaxies with Convolutional Ne.pdf;/Users/chahah/Zotero/storage/IBN27BEG/1902.html}
}
